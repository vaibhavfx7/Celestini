{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x[x.columns[17]]\n",
    "x=x.drop([x.columns[0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.drop([x.columns[16]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y:\n",
    "    if type(i) is str:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\virendra\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf1.score(X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', random_state=0, gamma=1, C=1)\n",
    "# Train the classifier\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=100, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='poly', random_state=, gamma=1, C=1)\n",
    "# Train the classifier\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='sigmoid', random_state=10, gamma=1, C=1)\n",
    "# Train the classifier\n",
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\virendra\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=16, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 1s 13ms/step - loss: -0.5525 - acc: 0.4000\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -1.0868 - acc: 0.4000\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -1.6220 - acc: 0.4000\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -2.1540 - acc: 0.4000\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -2.7919 - acc: 0.4000\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -3.4358 - acc: 0.4000\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -4.2635 - acc: 0.4000\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -5.0868 - acc: 0.4000\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -5.9707 - acc: 0.4000\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -7.0464 - acc: 0.4000\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -8.2933 - acc: 0.4000\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -9.8298 - acc: 0.4000\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 320us/step - loss: -11.7642 - acc: 0.4000\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -14.1589 - acc: 0.4000\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -16.9716 - acc: 0.4000\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -20.7132 - acc: 0.4000\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -24.4566 - acc: 0.4000\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -27.1372 - acc: 0.4000\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -28.0944 - acc: 0.4000\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -28.4411 - acc: 0.4000\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -28.5474 - acc: 0.4000\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -28.6626 - acc: 0.4000\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -28.7372 - acc: 0.4000\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -28.7996 - acc: 0.4000\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -28.8678 - acc: 0.4000\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -28.9311 - acc: 0.4000\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.0212 - acc: 0.4000\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.0909 - acc: 0.4000\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.1818 - acc: 0.4000\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.2276 - acc: 0.4000\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.3443 - acc: 0.4000\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4518 - acc: 0.4000\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4518 - acc: 0.4000\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - ETA: 0s - loss: -39.8560 - acc: 0.200 - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 320us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - ETA: 0s - loss: -31.8848 - acc: 0.200 - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - ETA: 0s - loss: -31.8848 - acc: 0.400 - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 83/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 160us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 200us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: -29.4934 - acc: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1b2b0e4a8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x, y)[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
